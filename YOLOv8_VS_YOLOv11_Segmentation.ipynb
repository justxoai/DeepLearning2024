{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justxoai/DeepLearning2024/blob/main/YOLOv8_VS_YOLOv11_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essential packages and libraries"
      ],
      "metadata": {
        "id": "zXnG_WCSAluY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "1. `roboflow` is where we download the dataset.\n",
        "2. `ultralytics` provides YOLO models. In this project, we will be using a YOLOv8 model and a YOLOv11 model."
      ],
      "metadata": {
        "id": "BzV3fnuoBEG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "!pip install -q ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2tjBkVyKDEKd",
        "outputId": "6c8bab98-90ff-4285-8d6f-2d9287c7986e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.45-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.45-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, idna, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.45\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m881.3/881.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tools for file and system operations"
      ],
      "metadata": {
        "id": "ePPdthFKifo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "mvIkXJzfJ0SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Not training related) Delete auto-generated sample data by google colab"
      ],
      "metadata": {
        "id": "Xh8V_mez738d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('sample_data', ignore_errors=True)"
      ],
      "metadata": {
        "id": "xWqt7fzTwUMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset\n",
        "Our dataset with a total of 343 images has already been splitted into 3 subsets, namely `train`, `valid` and `test`.\n",
        "- **train set** and **valid set** (70% and 20% respectively) will be used to train the model\n",
        "- **test set** (10%) will be used after the training process to compare actual results with the predicted results given by the model"
      ],
      "metadata": {
        "id": "0OdflmtXh5PV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and refactor folder names of dataset"
      ],
      "metadata": {
        "id": "KOIpGILu_3Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"???\") # Omitted for security reasons\n",
        "project = rf.workspace(\"kfupm-7hvnm\").project(\"lung-tumor-2xcgn\")\n",
        "version = project.version(3)\n",
        "\n",
        "current_folder_name = 'Lung-Tumor-3'\n",
        "dataset_name = 'dataset'\n",
        "\n",
        "v8seg_dataset_obj = version.download(\"yolov8\")\n",
        "os.rename(current_folder_name, dataset_name)\n",
        "print(f\"\\nFolder renamed from {current_folder_name} to {dataset_name}\")\n",
        "\n",
        "os.rename('/content/' + dataset_name + '/data.yaml', '/content/' + dataset_name + '/v8seg_data.yaml')\n",
        "\n",
        "v11seg_dataset_obj = version.download(\"yolov11\")\n",
        "shutil.move('/content/' + current_folder_name + '/data.yaml', '/content/' + dataset_name + '/v11seg_data.yaml')\n",
        "shutil.rmtree(current_folder_name)\n",
        "\n",
        "v8seg_dataset_path = os.path.join('/content/' + dataset_name, 'v8seg_data.yaml')\n",
        "v11seg_dataset_path = os.path.join('/content/' + dataset_name, 'v11seg_data.yaml')\n",
        "\n",
        "def replace_path_in_file(path: str):\n",
        "    with open(path, 'r') as file:\n",
        "        content = file.read()\n",
        "    content = content.replace(current_folder_name, '..')\n",
        "    with open(path, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "replace_path_in_file(v8seg_dataset_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qE-_rSZv1k8t",
        "outputId": "eeb5e7e4-37c9-479a-e864-eafa50fb4da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.3.1, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Lung-Tumor-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15183/15183 [00:01<00:00, 12456.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Lung-Tumor-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 698/698 [00:00<00:00, 1536.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Folder renamed from Lung-Tumor-3 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Lung-Tumor-3 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15183/15183 [00:01<00:00, 13257.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Lung-Tumor-3 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 698/698 [00:00<00:00, 1456.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete dataset folder if needed to re-download"
      ],
      "metadata": {
        "id": "JpW9kRFziko5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('dataset')"
      ],
      "metadata": {
        "id": "X-mq4Z1c1SgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "lbyYs9HviwmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_train(model, dataset_path, output_folder_name):\n",
        "    return model.train(\n",
        "        data = dataset_path,\n",
        "        project = output_folder_name,\n",
        "        name = '100_epochs',\n",
        "        epochs = 100,\n",
        "        patience = 10,\n",
        "        batch = 4,\n",
        "        imgsz = 640,\n",
        "        workers = 8\n",
        "    )"
      ],
      "metadata": {
        "id": "OQ8NpCXu93eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model Parameters\n",
        "In this topic, we are able to pass a number of arguments:\n",
        "\n",
        "- **`data:`** Data configuration\n",
        "\n",
        "    -> This parameter points to where the training data is stored, including both images and their corresponding labels.\n",
        "\n",
        "- **`project:`** Output directory\n",
        "\n",
        "    -> This parameter sets the project folder where training results (such as model weights and evaluation metrics) will be saved.\n",
        "\n",
        "- **`name:`** Subfolder\n",
        "\n",
        "    -> A subfolder within the project folder will be created with this name to store the results of this specific training run.\n",
        "\n",
        "- **`epochs:`** Define the number of training epochs\n",
        "\n",
        "    -> An epoch refers to one iteration over the entire training dataset. The more epochs, the more opportunities the model has to learn from the data. However, too many epochs can lead to overfitting.\n",
        "\n",
        "- **`patience:`**\n",
        "\n",
        "    -> The patience parameter controls how many epochs the training will continue after a metric (like validation loss) stops improving. It helps prevent overtraining and overfitting.\n",
        "\n",
        "- **`batch:`** Determine batch size  \n",
        "\n",
        "    -> Batch size defines how many samples will be processed before the model's weights are updated. Larger batch sizes may result in more stable training but require more memory (especially on GPUs). Smaller batch sizes can reduce memory usage but might introduce noise in the weight updates, which could affect convergence.\n",
        "\n",
        "- **`imgsz:`** Define input image size  \n",
        "\n",
        "    -> This specifies the size (in pixels) of the images that will be fed into the model. In this case, images will be resized to 640x640 before training. Larger images provide more detail but require more memory and computation time. Smaller images may speed up training but at the potential cost of losing important information.\n",
        "\n",
        "- **`workers:`**\n",
        "\n",
        "    -> Refers to the number of workers (parallel processes) used to load the data. More workers can speed up data loading during training."
      ],
      "metadata": {
        "id": "5IyoTFBzAlfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOLOv8\n",
        "\n",
        "- The line `v8seg_model = YOLO(\"yolov8x-seg.pt\")` is creating an instance of the YOLO model using a specific pre-trained model file, in this case, `yolov8x-seg.pt`.\n",
        "  - `yolov8x`: YOLO version 8 model in its \"extra large\" (`x`) configuration\n",
        "    - **65,193,619 parameters**\n",
        "    - **313 layers**\n",
        "  - `seg`: The model is specifically trained for segmentation tasks\n",
        "- `v8seg_dataset_path`: The path to its dataset configuration will be `/content/dataset/v8seg_data.yaml`\n",
        "- `v8seg_out`: The name of project folder"
      ],
      "metadata": {
        "id": "BgcN-jKyEzBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v8seg_model = YOLO(\"yolov8x-seg.pt\")\n",
        "v8seg_out = 'v8seg_out'\n",
        "v8seg_results = start_train(v8seg_model, v8seg_dataset_path, v8seg_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UKsiFalVDnuP",
        "outputId": "80208b3e-5568-49e7-ac22-f66abec57d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-seg.pt to 'yolov8x-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 137M/137M [00:01<00:00, 86.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.1 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8x-seg.pt, data=/content/dataset/v8seg_data.yaml, epochs=100, time=None, patience=10, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=v8seg_out, name=100_epochs, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=v8seg_out/100_epochs\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   5791731  ultralytics.nn.modules.head.Segment          [1, 32, 320, [320, 640, 640]] \n",
            "YOLOv8x-seg summary: 425 layers, 65,226,371 parameters, 65,226,355 gradients, 313.9 GFLOPs\n",
            "\n",
            "Transferred 615/693 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir v8seg_out/100_epochs', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed âŒ. Anomalies were detected with AMP on your system that may lead to NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train/labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels.cache... 69 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to v8seg_out/100_epochs/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 112 weight(decay=0.0), 123 weight(decay=0.0005), 122 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mv8seg_out/100_epochs\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      10.8G      1.759      1.993      3.657      1.159          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:04<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100        11G      1.954      1.703      2.974      1.309          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      10.9G      2.075      1.872      2.543      1.413          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      10.9G      2.054      2.341      2.717      1.419          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.207        0.1      0.073     0.0348      0.207        0.1     0.0701     0.0375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      10.9G      2.223      1.683      2.344      1.475          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70     0.0191     0.0143    0.00141   0.000466     0.0191     0.0143    0.00141   0.000555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      10.9G      2.197      1.817      2.011      1.414          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70     0.0191     0.0143    0.00141   0.000466     0.0191     0.0143    0.00141   0.000555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      10.9G      2.079      1.615      1.602      1.349          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:02<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.76      0.429      0.566      0.203      0.601      0.343      0.385      0.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      10.9G      2.011      1.666      1.498      1.369          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.787      0.528      0.627      0.206      0.638      0.428      0.448      0.138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      10.9G      1.923      1.712      1.319      1.299          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:04<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.945     0.0857     0.0965     0.0372      0.381     0.0857     0.0843     0.0346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      10.9G      1.982      1.605       1.37      1.372          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.744      0.114      0.132     0.0591      0.744      0.114      0.132     0.0466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      10.9G      1.907      1.539      1.259      1.302         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.821      0.857      0.845       0.36      0.776      0.814      0.796      0.253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      10.9G      1.801      1.696       1.16      1.217          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.819      0.857       0.86      0.385      0.791      0.829      0.817      0.309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      10.9G      1.812      1.389      1.097      1.266          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.913      0.829      0.896      0.389      0.847       0.79      0.821      0.316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      10.9G      1.899      1.607      1.131      1.329          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.916      0.782      0.821      0.319      0.817        0.7      0.701      0.209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      10.9G      1.822      1.657      1.195      1.221          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.79      0.485      0.493      0.204      0.622      0.376      0.382      0.137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      10.9G       1.96      1.375      1.095      1.337          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.938      0.871      0.904      0.398      0.861        0.8      0.818      0.269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      10.9G       1.89      1.625      1.068      1.255          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70        0.9      0.871      0.933      0.419      0.869      0.843      0.885      0.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      10.9G       1.79      1.419     0.9792      1.246          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.946      0.857      0.922      0.433      0.862      0.786      0.833      0.322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      10.9G      1.787      1.331      1.003      1.268          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.862      0.893      0.876      0.397      0.834      0.861      0.865      0.319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      10.9G      1.688       1.68     0.9208      1.213          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.908      0.847      0.916      0.373      0.726      0.686      0.708      0.218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      10.9G      1.858      1.659     0.9401      1.282          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.903      0.927      0.925      0.415       0.94      0.894      0.908      0.385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      10.9G      1.702      1.404     0.9047      1.194          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.951      0.686      0.765      0.324      0.867      0.629      0.671      0.226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      10.9G      1.704      1.544     0.8845      1.209          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:04<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.924        0.9       0.91      0.403      0.924        0.9      0.899      0.353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      10.9G      1.801      1.525     0.8975       1.26          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.955      0.914      0.904      0.377      0.835        0.8      0.782      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      10.9G      1.662      1.356     0.8744      1.228          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:04<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.956      0.928      0.931      0.399      0.853      0.828      0.832      0.327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      10.9G      1.745      1.459     0.8904      1.213          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.892      0.814       0.88      0.384      0.829      0.757       0.79      0.256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      10.9G      1.667      1.288     0.8209      1.182          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:02<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.94      0.771      0.774      0.327      0.826       0.68      0.658      0.271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      10.9G      1.779      1.549     0.9828      1.246          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:02<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.873      0.782      0.777      0.322      0.809      0.728      0.669      0.224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      10.9G      1.723       1.43     0.9016      1.175          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.942      0.928      0.957      0.424      0.848      0.814      0.837      0.275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      10.9G      1.731      1.644     0.8302      1.193          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.985      0.952      0.978      0.405      0.867      0.835      0.846      0.306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      10.9G       1.75      1.512     0.8847      1.235          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:03<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.93      0.957      0.952      0.424      0.875        0.9      0.919      0.357\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 21, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "31 epochs completed in 0.802 hours.\n",
            "Optimizer stripped from v8seg_out/100_epochs/weights/last.pt, 130.9MB\n",
            "Optimizer stripped from v8seg_out/100_epochs/weights/best.pt, 130.9MB\n",
            "\n",
            "Validating v8seg_out/100_epochs/weights/best.pt...\n",
            "Ultralytics 8.3.1 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8x-seg summary (fused): 313 layers, 65,193,619 parameters, 0 gradients, 313.0 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.903      0.928      0.925      0.415       0.94      0.894      0.908      0.385\n",
            "Speed: 0.7ms preprocess, 85.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mv8seg_out/100_epochs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete project folder if needed to do another train"
      ],
      "metadata": {
        "id": "FOlmqwuqN3WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('v8seg_out')"
      ],
      "metadata": {
        "id": "dg9TQS8wKCRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOLO11\n",
        "\n",
        "- The line `v11seg_model = YOLO(\"yolo11x-seg.pt\")` is creating an instance of the YOLO model using a specific pre-trained model file, in this case, `yolo11x-seg.pt`.\n",
        "  - `yolo11x`: YOLO version 11 model in its \"extra large\" (`x`) configuration\n",
        "    - **62,003,283 parameters**\n",
        "    - **491 layers**\n",
        "  - `seg`: The model is specifically trained for segmentation tasks\n",
        "- `v11seg_dataset_path`: The path to its dataset configuration will be `/content/dataset/v11seg_data.yaml`\n",
        "- `v11seg_out`: The name of project folder"
      ],
      "metadata": {
        "id": "Mis5GeRnOjsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v11seg_model = YOLO(\"yolo11x-seg.pt\")\n",
        "v11seg_out = 'v11seg_out'\n",
        "v11seg_results = start_train(v11seg_model, v11seg_dataset_path, v11seg_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "04nfrt9dH4Sa",
        "outputId": "8fd5f897-b0f6-4881-b6fc-bfc2f44b3f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-seg.pt to 'yolo11x-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119M/119M [00:03<00:00, 38.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.1 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11x-seg.pt, data=/content/dataset/v11seg_data.yaml, epochs=100, time=None, patience=10, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=v11seg_out, name=100_epochs, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=v11seg_out/100_epochs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 25.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
            "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
            "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
            "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
            " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
            " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
            " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
            " 23        [16, 19, 22]  1   8323187  ultralytics.nn.modules.head.Segment          [1, 32, 384, [384, 768, 768]] \n",
            "YOLO11x-seg summary: 667 layers, 62,051,411 parameters, 62,051,395 gradients, 319.7 GFLOPs\n",
            "\n",
            "Transferred 1071/1077 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir v11seg_out/100_epochs', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 111MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ yolo11n.pt appears to require 'dill', which is not in Ultralytics requirements.\n",
            "AutoInstall will run now for 'dill' but this feature will be removed in the future.\n",
            "Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official Ultralytics model, i.e. 'yolo predict model=yolov8n.pt'\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 119.4/119.4 kB 6.2 MB/s eta 0:00:00\n",
            "Installing collected packages: dill\n",
            "Successfully installed dill-0.3.9\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 2.8s, installed 1 package: ['dill']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed âŒ. Anomalies were detected with AMP on your system that may lead to NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:00<00:00, 1673.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of Albumentations is available: 1.4.17 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels... 69 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:00<00:00, 1231.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to v11seg_out/100_epochs/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 176 weight(decay=0.0), 187 weight(decay=0.0005), 186 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mv11seg_out/100_epochs\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      11.1G      1.908      2.159      3.914      1.303          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:07<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      10.4G      2.151      2.262      3.535      1.383          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:06<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      10.4G      2.555      1.904      4.059      1.717          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      10.4G      2.463      2.316      4.534      1.689          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      10.4G      2.603      1.978      5.887      1.745          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70   0.000426        0.1   0.000242   6.48e-05   0.000591      0.143   0.000368   0.000107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      10.4G      2.383      2.132      2.275      1.533          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.249        0.2      0.121     0.0371       0.23      0.186      0.096     0.0332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      10.4G      2.193      1.683      1.734      1.431          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.647     0.0857     0.0756     0.0317       0.36     0.0724     0.0659      0.021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      10.4G      2.188      1.719      1.626      1.465          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.771        0.7      0.787      0.267      0.797      0.557       0.68      0.208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      10.4G      2.072      1.692      1.486       1.39          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.562      0.367      0.346      0.106      0.475       0.31      0.266     0.0858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      10.4G      2.041      1.588      1.469      1.421          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.53      0.457      0.505      0.206      0.546      0.443      0.488      0.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      10.4G      2.107      1.608      1.458      1.417         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.732      0.714      0.704      0.246      0.614      0.643      0.601       0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      10.4G      1.964      1.652      1.288      1.335          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70        0.8      0.486      0.519      0.181      0.775      0.457      0.478       0.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      10.4G      2.029      1.537      1.259      1.379          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.875      0.629      0.741      0.293      0.856      0.614      0.734      0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      10.4G      2.042      1.483      1.304      1.429          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.764      0.614      0.692      0.226      0.591      0.486       0.47      0.114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      10.4G      1.966      1.619      1.193      1.296          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.877      0.586      0.739      0.294      0.709      0.657      0.687       0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      10.4G      1.948       1.29       1.24      1.344          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:10<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.818      0.557      0.663      0.241      0.642      0.462      0.514      0.149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      10.4G      1.964      1.725      1.226      1.289          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.844      0.829      0.872      0.366       0.77      0.757      0.791      0.304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      10.4G      1.905      1.513      1.141      1.311          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:10<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.949      0.814      0.913      0.413      0.926      0.786      0.906      0.353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      10.4G      1.836      1.345      1.064      1.307          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.869      0.856        0.9       0.36        0.8      0.799      0.803      0.256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      10.4G      1.751      1.496      1.052      1.252          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.909      0.871      0.896      0.371      0.879      0.843      0.851      0.277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      10.4G      1.936      1.662      1.109      1.334          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:10<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.962      0.743      0.814      0.351      0.833      0.643      0.689      0.267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      10.4G      1.719      1.378      1.004      1.218          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.96      0.914      0.952      0.417      0.838        0.8      0.777      0.304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      10.4G      1.817      1.503      0.922      1.266          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.43      0.657      0.379      0.159      0.418      0.643      0.354      0.129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      10.4G      1.915      1.447      1.079      1.317          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.926      0.929       0.94      0.398      0.814      0.729      0.774      0.271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      10.4G      1.752      1.376     0.9601      1.278          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70       0.88      0.671      0.736      0.294      0.806      0.614      0.613      0.188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      10.4G      1.865      1.449     0.9502       1.26          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:10<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.784     0.0571     0.0535     0.0151      0.588     0.0429      0.034     0.0151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      10.4G       1.72      1.294     0.8802      1.208          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:09<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.903      0.801      0.884      0.371      0.855      0.759      0.796      0.286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      10.4G      1.856      1.534     0.9229      1.276          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:10<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.944      0.871      0.891      0.407      0.867        0.8      0.783      0.264\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 18, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "28 epochs completed in 0.719 hours.\n",
            "Optimizer stripped from v11seg_out/100_epochs/weights/last.pt, 124.8MB\n",
            "Optimizer stripped from v11seg_out/100_epochs/weights/best.pt, 124.8MB\n",
            "\n",
            "Validating v11seg_out/100_epochs/weights/best.pt...\n",
            "Ultralytics 8.3.1 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11x-seg summary (fused): 491 layers, 62,003,283 parameters, 0 gradients, 318.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         69         70      0.949      0.814      0.913      0.413      0.927      0.786      0.906      0.353\n",
            "Speed: 0.3ms preprocess, 90.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mv11seg_out/100_epochs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete project folder if needed to do another train"
      ],
      "metadata": {
        "id": "obZdAJYfNi5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('v11seg_out')"
      ],
      "metadata": {
        "id": "Hln12nYtKOnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post Training Activities"
      ],
      "metadata": {
        "id": "yiLg8nSYOLXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draw Actual Images from **Test set**\n",
        "Images and labels are provided by the dataset."
      ],
      "metadata": {
        "id": "ROBMxPr9mrTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def draw_actual(images_folder, labels_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through all image files in the images folder\n",
        "    for image_file in os.listdir(images_folder):\n",
        "        if image_file.endswith(('.jpg', '.jpeg', '.png')):  # Check for image file extensions\n",
        "            # Load the image\n",
        "            image_path = os.path.join(images_folder, image_file)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Load the segmentation label\n",
        "            label_path = os.path.join(labels_folder, os.path.splitext(image_file)[0] + '.txt')\n",
        "            height, width, _ = image.shape\n",
        "\n",
        "            # Check if label file exists\n",
        "            if not os.path.exists(label_path):\n",
        "                print(f\"Label file {label_path} does not exist. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            with open(label_path, 'r') as file:\n",
        "                labels = file.readlines()\n",
        "\n",
        "            # Iterate through each object in the label\n",
        "            for label in labels:\n",
        "                label = label.strip().split()\n",
        "                class_id = int(label[0])\n",
        "                polygon_coords = list(map(float, label[1:]))\n",
        "\n",
        "                # Reshape polygon coordinates\n",
        "                polygon = np.array(polygon_coords).reshape(-1, 2)\n",
        "                polygon[:, 0] = polygon[:, 0] * width  # Convert normalized x to pixel x\n",
        "                polygon[:, 1] = polygon[:, 1] * height # Convert normalized y to pixel y\n",
        "                polygon = polygon.astype(np.int32)\n",
        "\n",
        "                # Draw the polygon mask on the image (for visualization)\n",
        "                cv2.polylines(image, [polygon], isClosed=True, color=(0, 0, 255), thickness=2)\n",
        "                cv2.fillPoly(image, [polygon], color=(255, 0, 255))  # Draw the filled mask\n",
        "\n",
        "            # Save the modified image\n",
        "            output_image_path = os.path.join(output_folder, image_file)\n",
        "            save_success = cv2.imwrite(output_image_path, image)\n",
        "\n",
        "            if save_success:\n",
        "                print(f\"Image saved successfully at {output_image_path}\")\n",
        "            else:\n",
        "                print(f\"Failed to save the image at {output_image_path}\")"
      ],
      "metadata": {
        "id": "ltHDGoJbT-Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = \"/content/dataset/test/images\"\n",
        "labels = \"/content/dataset/test/labels\"\n",
        "output = \"/content/dataset/test/actual\"\n",
        "\n",
        "draw_actual(images, labels, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lSR13zSwUfHV",
        "outputId": "535c33e2-dcac-4f47-a168-4c92c709119b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved successfully at /content/dataset/test/actual/003380_03_01_140_png_jpg.rf.f79c35e472e03b850cd573ff0dd8b253.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000103_13_01_019_png_jpg.rf.9ab571abaf8f3b70b259dec2ba63f4f5.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000306_06_02_126_png_jpg.rf.38ae65457b77dc15f7ed15d72984b396.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000103_08_01_016_png_jpg.rf.6fff7bdb9e44d43c7c96680912780e93.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000874_03_02_219_png_jpg.rf.1447e1d2cca9a1bd99d429f6a06f4648.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/001404_01_01_139_png_jpg.rf.286b22d8ea74a86732ab9397d3553be4.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000103_02_01_060_png_jpg.rf.e45c32f9edd4abfe3b94915ccbb256fd.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/002265_02_01_031_png_jpg.rf.cac17609de187598bd537354b0ce3e75.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/001083_09_01_093_png_jpg.rf.8e1523e1e214bb04a5c296ced316db62.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000021_02_01_068_png_jpg.rf.1a5ef4b2969421b2fb1e65728d0bf2b0.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000143_04_02_083_png_jpg.rf.ec2e44b5bc08568e24a94ad09d4f58fd.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/003038_05_01_063_png_jpg.rf.befa5a560dd5db6e6f38b4472098e310.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000223_05_03_128_png_jpg.rf.65ceaaeff9d3fa775110d5ac73273ea3.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000238_10_02_152_png_jpg.rf.d457ea4c7fa23b0da0abc93536627fc8.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000223_07_01_133_png_jpg.rf.7104f50e578370818e068a79e08104f8.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000328_08_03_180_png_jpg.rf.3f6c5db69462e24c02a18ec8589b11b3.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000238_09_03_124_png_jpg.rf.dcf39b121afb05c7fde8cfade202d2fa.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000247_04_01_165_png_jpg.rf.2821dca1fdaab8b22c37ecc944d7ce55.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000103_07_02_160_png_jpg.rf.d20feac44afefd7fe6931ef1456d8066.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000188_03_01_146_png_jpg.rf.0aa9c26b627618f4d2c83082b4ed4ef2.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000238_09_03_268_png_jpg.rf.f09aa86ad3ea702195bd5f35eddd1212.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000247_06_02_201_png_jpg.rf.ef1caa3c734b81d91b329bb15e106192.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000143_04_02_126_png_jpg.rf.a0d17c3818d84c51f0d6c14517c6dc00.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000103_10_01_166_png_jpg.rf.a4b7ce6d23f601c2ad41c03fa6c23f03.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000247_06_02_149_png_jpg.rf.4a87a4b933d17a7ef8f7cf8e81ec9de2.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000207_04_01_059_png_jpg.rf.80eef1da822745c5220074d7aa04de5f.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000021_03_01_017_png_jpg.rf.6ed5f9db45f94150d050893798c7ee25.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000103_11_01_177_png_jpg.rf.81d2f65ea3a0de1b20c4e96430b15374.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000304_01_01_210_png_jpg.rf.5385972414977833b61eff488f5e2bd1.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000103_02_01_168_png_jpg.rf.76e5e9fffd849b95bf96ae1ed4b1be65.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/002408_01_01_161_png_jpg.rf.5ab3f5970d7b18ffb4c76a1a9acbf4a9.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000020_04_01_143_png_jpg.rf.1979d244d1b2bc2c7a61d94fd98cf13e.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000230_05_01_165_png_jpg.rf.785131d9ef12d61057eadfd5e6b257ca.jpg\n",
            "Image saved successfully at /content/dataset/test/actual/000284_02_02_018_png_jpg.rf.19c0aaac855fbc821a82306c3d92f86e.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draw Predicted Images from **Test set**\n",
        "Images are provided by the dataset, but the labels will be predicted by our previously trained model"
      ],
      "metadata": {
        "id": "-qMg_I3OmufK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def draw_predicted(images_folder, trained_model, output_folder):\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through all image files in the images folder\n",
        "    for image_file in os.listdir(images_folder):\n",
        "        if image_file.endswith(('.jpg', '.jpeg', '.png')):  # Check for image file extensions\n",
        "            # Load the image\n",
        "            image_path = os.path.join(images_folder, image_file)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Predict with the model\n",
        "            results = trained_model(image_path)  # Predict on the image file\n",
        "\n",
        "            # Iterate through the results\n",
        "            for result in results:\n",
        "                masks = result.masks  # Get masks from results\n",
        "                names = trained_model.names  # Get class names from the model\n",
        "\n",
        "                # Draw the masks on the image\n",
        "                if masks is not None and masks.data is not None:\n",
        "                    for i in range(masks.data.shape[0]):  # Iterate over each mask\n",
        "                        mask_array = masks.data[i].cpu().numpy()  # Get mask data as NumPy array\n",
        "                        mask_array = (mask_array > 0).astype(np.uint8)  # Binarize the mask\n",
        "\n",
        "                        # Create a red color version of the mask\n",
        "                        colored_mask = np.zeros_like(image)  # Create an empty image with the same shape\n",
        "                        colored_mask[mask_array == 1] = [0, 255, 255]  # Set the mask region to red\n",
        "\n",
        "                        # Blend the mask with the original image\n",
        "                        alpha = 0.5  # Adjust transparency\n",
        "                        blended = cv2.addWeighted(image, 1 - alpha, colored_mask, alpha, 0)\n",
        "\n",
        "                        # Update the original image with the blended mask\n",
        "                        image = blended\n",
        "\n",
        "                        # Access confidence and class using boxes\n",
        "                        if result.boxes is not None:\n",
        "                            conf = result.boxes[i].conf.item()  # Confidence score\n",
        "                            cls = result.boxes[i].cls.item()  # Class index\n",
        "                            class_name = names[int(cls)]  # Get class name from index\n",
        "\n",
        "                            # Calculate the position to draw the text (using mask's centroid)\n",
        "                            y, x = np.where(mask_array == 1)  # Get coordinates of the mask\n",
        "                            if len(x) > 0 and len(y) > 0:  # Check if there are any coordinates\n",
        "                                text_x, text_y = int(x.mean()), int(y.mean())  # Get the centroid for text position\n",
        "                                # Draw the class name and confidence next to the mask\n",
        "                                cv2.putText(image, f'{class_name}: {conf:.2f}',\n",
        "                                            (text_x, text_y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                            1, (255, 255, 0), 2)\n",
        "\n",
        "            # Save the modified image\n",
        "            output_image_path = os.path.join(output_folder, image_file)\n",
        "            save_success = cv2.imwrite(output_image_path, image)\n",
        "\n",
        "            if save_success:\n",
        "                print(f\"Image saved successfully at {output_image_path}\")\n",
        "            else:\n",
        "                print(f\"Failed to save the image at {output_image_path}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nv9OLq5pXL4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = \"/content/dataset/test/images\"\n",
        "\n",
        "# YOLOv8\n",
        "model = YOLO(\"/content/v8seg_out/100_epochs/weights/best.pt\")\n",
        "output = \"/content/dataset/test/v8predict\"\n",
        "draw_predicted(images, model, output)\n",
        "\n",
        "# YOLO11\n",
        "model = YOLO(\"/content/v11seg_out/100_epochs/weights/best.pt\")\n",
        "output = \"/content/dataset/test/v11predict\"\n",
        "draw_predicted(images, model, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DP1LoR_mYYgt",
        "outputId": "c9bf0f74-90a9-460d-9a38-99497c032fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/test/images/003380_03_01_140_png_jpg.rf.f79c35e472e03b850cd573ff0dd8b253.jpg: 640x640 1 Tumor, 110.5ms\n",
            "Speed: 2.0ms preprocess, 110.5ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/003380_03_01_140_png_jpg.rf.f79c35e472e03b850cd573ff0dd8b253.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_13_01_019_png_jpg.rf.9ab571abaf8f3b70b259dec2ba63f4f5.jpg: 640x640 1 Tumor, 67.0ms\n",
            "Speed: 1.9ms preprocess, 67.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000103_13_01_019_png_jpg.rf.9ab571abaf8f3b70b259dec2ba63f4f5.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000306_06_02_126_png_jpg.rf.38ae65457b77dc15f7ed15d72984b396.jpg: 640x640 2 Tumors, 69.0ms\n",
            "Speed: 1.7ms preprocess, 69.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000306_06_02_126_png_jpg.rf.38ae65457b77dc15f7ed15d72984b396.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_08_01_016_png_jpg.rf.6fff7bdb9e44d43c7c96680912780e93.jpg: 640x640 1 Tumor, 67.9ms\n",
            "Speed: 1.5ms preprocess, 67.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000103_08_01_016_png_jpg.rf.6fff7bdb9e44d43c7c96680912780e93.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000874_03_02_219_png_jpg.rf.1447e1d2cca9a1bd99d429f6a06f4648.jpg: 640x640 1 Tumor, 68.2ms\n",
            "Speed: 1.5ms preprocess, 68.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000874_03_02_219_png_jpg.rf.1447e1d2cca9a1bd99d429f6a06f4648.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/001404_01_01_139_png_jpg.rf.286b22d8ea74a86732ab9397d3553be4.jpg: 640x640 1 Tumor, 70.1ms\n",
            "Speed: 1.5ms preprocess, 70.1ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/001404_01_01_139_png_jpg.rf.286b22d8ea74a86732ab9397d3553be4.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_02_01_060_png_jpg.rf.e45c32f9edd4abfe3b94915ccbb256fd.jpg: 640x640 1 Tumor, 68.4ms\n",
            "Speed: 2.1ms preprocess, 68.4ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000103_02_01_060_png_jpg.rf.e45c32f9edd4abfe3b94915ccbb256fd.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/002265_02_01_031_png_jpg.rf.cac17609de187598bd537354b0ce3e75.jpg: 640x640 1 Tumor, 67.3ms\n",
            "Speed: 3.7ms preprocess, 67.3ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/002265_02_01_031_png_jpg.rf.cac17609de187598bd537354b0ce3e75.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/001083_09_01_093_png_jpg.rf.8e1523e1e214bb04a5c296ced316db62.jpg: 640x640 1 Tumor, 67.9ms\n",
            "Speed: 2.0ms preprocess, 67.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/001083_09_01_093_png_jpg.rf.8e1523e1e214bb04a5c296ced316db62.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000021_02_01_068_png_jpg.rf.1a5ef4b2969421b2fb1e65728d0bf2b0.jpg: 640x640 (no detections), 67.5ms\n",
            "Speed: 1.9ms preprocess, 67.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000021_02_01_068_png_jpg.rf.1a5ef4b2969421b2fb1e65728d0bf2b0.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000143_04_02_083_png_jpg.rf.ec2e44b5bc08568e24a94ad09d4f58fd.jpg: 640x640 1 Tumor, 70.1ms\n",
            "Speed: 1.9ms preprocess, 70.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000143_04_02_083_png_jpg.rf.ec2e44b5bc08568e24a94ad09d4f58fd.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/003038_05_01_063_png_jpg.rf.befa5a560dd5db6e6f38b4472098e310.jpg: 640x640 1 Tumor, 74.6ms\n",
            "Speed: 2.2ms preprocess, 74.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/003038_05_01_063_png_jpg.rf.befa5a560dd5db6e6f38b4472098e310.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000223_05_03_128_png_jpg.rf.65ceaaeff9d3fa775110d5ac73273ea3.jpg: 640x640 2 Tumors, 68.9ms\n",
            "Speed: 2.0ms preprocess, 68.9ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000223_05_03_128_png_jpg.rf.65ceaaeff9d3fa775110d5ac73273ea3.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000238_10_02_152_png_jpg.rf.d457ea4c7fa23b0da0abc93536627fc8.jpg: 640x640 1 Tumor, 66.0ms\n",
            "Speed: 2.0ms preprocess, 66.0ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000238_10_02_152_png_jpg.rf.d457ea4c7fa23b0da0abc93536627fc8.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000223_07_01_133_png_jpg.rf.7104f50e578370818e068a79e08104f8.jpg: 640x640 1 Tumor, 65.7ms\n",
            "Speed: 4.1ms preprocess, 65.7ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000223_07_01_133_png_jpg.rf.7104f50e578370818e068a79e08104f8.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000328_08_03_180_png_jpg.rf.3f6c5db69462e24c02a18ec8589b11b3.jpg: 640x640 1 Tumor, 66.3ms\n",
            "Speed: 2.5ms preprocess, 66.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000328_08_03_180_png_jpg.rf.3f6c5db69462e24c02a18ec8589b11b3.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000238_09_03_124_png_jpg.rf.dcf39b121afb05c7fde8cfade202d2fa.jpg: 640x640 1 Tumor, 67.7ms\n",
            "Speed: 2.0ms preprocess, 67.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000238_09_03_124_png_jpg.rf.dcf39b121afb05c7fde8cfade202d2fa.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000247_04_01_165_png_jpg.rf.2821dca1fdaab8b22c37ecc944d7ce55.jpg: 640x640 1 Tumor, 68.2ms\n",
            "Speed: 2.0ms preprocess, 68.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000247_04_01_165_png_jpg.rf.2821dca1fdaab8b22c37ecc944d7ce55.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_07_02_160_png_jpg.rf.d20feac44afefd7fe6931ef1456d8066.jpg: 640x640 1 Tumor, 67.0ms\n",
            "Speed: 2.0ms preprocess, 67.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000103_07_02_160_png_jpg.rf.d20feac44afefd7fe6931ef1456d8066.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000188_03_01_146_png_jpg.rf.0aa9c26b627618f4d2c83082b4ed4ef2.jpg: 640x640 1 Tumor, 66.8ms\n",
            "Speed: 2.0ms preprocess, 66.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000188_03_01_146_png_jpg.rf.0aa9c26b627618f4d2c83082b4ed4ef2.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000238_09_03_268_png_jpg.rf.f09aa86ad3ea702195bd5f35eddd1212.jpg: 640x640 1 Tumor, 67.6ms\n",
            "Speed: 2.0ms preprocess, 67.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000238_09_03_268_png_jpg.rf.f09aa86ad3ea702195bd5f35eddd1212.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000247_06_02_201_png_jpg.rf.ef1caa3c734b81d91b329bb15e106192.jpg: 640x640 1 Tumor, 68.2ms\n",
            "Speed: 1.9ms preprocess, 68.2ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000247_06_02_201_png_jpg.rf.ef1caa3c734b81d91b329bb15e106192.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000143_04_02_126_png_jpg.rf.a0d17c3818d84c51f0d6c14517c6dc00.jpg: 640x640 1 Tumor, 67.2ms\n",
            "Speed: 2.0ms preprocess, 67.2ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000143_04_02_126_png_jpg.rf.a0d17c3818d84c51f0d6c14517c6dc00.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_10_01_166_png_jpg.rf.a4b7ce6d23f601c2ad41c03fa6c23f03.jpg: 640x640 1 Tumor, 68.0ms\n",
            "Speed: 1.7ms preprocess, 68.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000103_10_01_166_png_jpg.rf.a4b7ce6d23f601c2ad41c03fa6c23f03.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000247_06_02_149_png_jpg.rf.4a87a4b933d17a7ef8f7cf8e81ec9de2.jpg: 640x640 1 Tumor, 68.1ms\n",
            "Speed: 2.0ms preprocess, 68.1ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000247_06_02_149_png_jpg.rf.4a87a4b933d17a7ef8f7cf8e81ec9de2.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000207_04_01_059_png_jpg.rf.80eef1da822745c5220074d7aa04de5f.jpg: 640x640 1 Tumor, 68.3ms\n",
            "Speed: 2.1ms preprocess, 68.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000207_04_01_059_png_jpg.rf.80eef1da822745c5220074d7aa04de5f.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000021_03_01_017_png_jpg.rf.6ed5f9db45f94150d050893798c7ee25.jpg: 640x640 1 Tumor, 68.2ms\n",
            "Speed: 2.0ms preprocess, 68.2ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000021_03_01_017_png_jpg.rf.6ed5f9db45f94150d050893798c7ee25.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_11_01_177_png_jpg.rf.81d2f65ea3a0de1b20c4e96430b15374.jpg: 640x640 1 Tumor, 67.0ms\n",
            "Speed: 2.0ms preprocess, 67.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000103_11_01_177_png_jpg.rf.81d2f65ea3a0de1b20c4e96430b15374.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000304_01_01_210_png_jpg.rf.5385972414977833b61eff488f5e2bd1.jpg: 640x640 1 Tumor, 68.9ms\n",
            "Speed: 1.9ms preprocess, 68.9ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000304_01_01_210_png_jpg.rf.5385972414977833b61eff488f5e2bd1.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_02_01_168_png_jpg.rf.76e5e9fffd849b95bf96ae1ed4b1be65.jpg: 640x640 (no detections), 68.2ms\n",
            "Speed: 1.9ms preprocess, 68.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000103_02_01_168_png_jpg.rf.76e5e9fffd849b95bf96ae1ed4b1be65.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/002408_01_01_161_png_jpg.rf.5ab3f5970d7b18ffb4c76a1a9acbf4a9.jpg: 640x640 2 Tumors, 68.7ms\n",
            "Speed: 4.7ms preprocess, 68.7ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/002408_01_01_161_png_jpg.rf.5ab3f5970d7b18ffb4c76a1a9acbf4a9.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000020_04_01_143_png_jpg.rf.1979d244d1b2bc2c7a61d94fd98cf13e.jpg: 640x640 1 Tumor, 68.0ms\n",
            "Speed: 1.9ms preprocess, 68.0ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000020_04_01_143_png_jpg.rf.1979d244d1b2bc2c7a61d94fd98cf13e.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000230_05_01_165_png_jpg.rf.785131d9ef12d61057eadfd5e6b257ca.jpg: 640x640 1 Tumor, 67.9ms\n",
            "Speed: 1.9ms preprocess, 67.9ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000230_05_01_165_png_jpg.rf.785131d9ef12d61057eadfd5e6b257ca.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000284_02_02_018_png_jpg.rf.19c0aaac855fbc821a82306c3d92f86e.jpg: 640x640 1 Tumor, 65.4ms\n",
            "Speed: 2.0ms preprocess, 65.4ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v8predict/000284_02_02_018_png_jpg.rf.19c0aaac855fbc821a82306c3d92f86e.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/003380_03_01_140_png_jpg.rf.f79c35e472e03b850cd573ff0dd8b253.jpg: 640x640 1 Tumor, 82.1ms\n",
            "Speed: 1.9ms preprocess, 82.1ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/003380_03_01_140_png_jpg.rf.f79c35e472e03b850cd573ff0dd8b253.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_13_01_019_png_jpg.rf.9ab571abaf8f3b70b259dec2ba63f4f5.jpg: 640x640 1 Tumor, 72.8ms\n",
            "Speed: 2.1ms preprocess, 72.8ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000103_13_01_019_png_jpg.rf.9ab571abaf8f3b70b259dec2ba63f4f5.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000306_06_02_126_png_jpg.rf.38ae65457b77dc15f7ed15d72984b396.jpg: 640x640 1 Tumor, 73.7ms\n",
            "Speed: 2.0ms preprocess, 73.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000306_06_02_126_png_jpg.rf.38ae65457b77dc15f7ed15d72984b396.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_08_01_016_png_jpg.rf.6fff7bdb9e44d43c7c96680912780e93.jpg: 640x640 1 Tumor, 74.2ms\n",
            "Speed: 2.6ms preprocess, 74.2ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000103_08_01_016_png_jpg.rf.6fff7bdb9e44d43c7c96680912780e93.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000874_03_02_219_png_jpg.rf.1447e1d2cca9a1bd99d429f6a06f4648.jpg: 640x640 1 Tumor, 75.6ms\n",
            "Speed: 2.0ms preprocess, 75.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000874_03_02_219_png_jpg.rf.1447e1d2cca9a1bd99d429f6a06f4648.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/001404_01_01_139_png_jpg.rf.286b22d8ea74a86732ab9397d3553be4.jpg: 640x640 1 Tumor, 76.3ms\n",
            "Speed: 2.0ms preprocess, 76.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/001404_01_01_139_png_jpg.rf.286b22d8ea74a86732ab9397d3553be4.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_02_01_060_png_jpg.rf.e45c32f9edd4abfe3b94915ccbb256fd.jpg: 640x640 1 Tumor, 75.1ms\n",
            "Speed: 2.0ms preprocess, 75.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000103_02_01_060_png_jpg.rf.e45c32f9edd4abfe3b94915ccbb256fd.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/002265_02_01_031_png_jpg.rf.cac17609de187598bd537354b0ce3e75.jpg: 640x640 1 Tumor, 74.3ms\n",
            "Speed: 2.1ms preprocess, 74.3ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/002265_02_01_031_png_jpg.rf.cac17609de187598bd537354b0ce3e75.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/001083_09_01_093_png_jpg.rf.8e1523e1e214bb04a5c296ced316db62.jpg: 640x640 1 Tumor, 76.3ms\n",
            "Speed: 2.2ms preprocess, 76.3ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/001083_09_01_093_png_jpg.rf.8e1523e1e214bb04a5c296ced316db62.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000021_02_01_068_png_jpg.rf.1a5ef4b2969421b2fb1e65728d0bf2b0.jpg: 640x640 (no detections), 76.5ms\n",
            "Speed: 1.9ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000021_02_01_068_png_jpg.rf.1a5ef4b2969421b2fb1e65728d0bf2b0.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000143_04_02_083_png_jpg.rf.ec2e44b5bc08568e24a94ad09d4f58fd.jpg: 640x640 1 Tumor, 77.3ms\n",
            "Speed: 2.0ms preprocess, 77.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000143_04_02_083_png_jpg.rf.ec2e44b5bc08568e24a94ad09d4f58fd.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/003038_05_01_063_png_jpg.rf.befa5a560dd5db6e6f38b4472098e310.jpg: 640x640 1 Tumor, 75.4ms\n",
            "Speed: 2.0ms preprocess, 75.4ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/003038_05_01_063_png_jpg.rf.befa5a560dd5db6e6f38b4472098e310.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000223_05_03_128_png_jpg.rf.65ceaaeff9d3fa775110d5ac73273ea3.jpg: 640x640 1 Tumor, 73.2ms\n",
            "Speed: 2.3ms preprocess, 73.2ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000223_05_03_128_png_jpg.rf.65ceaaeff9d3fa775110d5ac73273ea3.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000238_10_02_152_png_jpg.rf.d457ea4c7fa23b0da0abc93536627fc8.jpg: 640x640 2 Tumors, 76.8ms\n",
            "Speed: 2.2ms preprocess, 76.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000238_10_02_152_png_jpg.rf.d457ea4c7fa23b0da0abc93536627fc8.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000223_07_01_133_png_jpg.rf.7104f50e578370818e068a79e08104f8.jpg: 640x640 2 Tumors, 73.7ms\n",
            "Speed: 2.0ms preprocess, 73.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000223_07_01_133_png_jpg.rf.7104f50e578370818e068a79e08104f8.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000328_08_03_180_png_jpg.rf.3f6c5db69462e24c02a18ec8589b11b3.jpg: 640x640 1 Tumor, 73.1ms\n",
            "Speed: 1.9ms preprocess, 73.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000328_08_03_180_png_jpg.rf.3f6c5db69462e24c02a18ec8589b11b3.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000238_09_03_124_png_jpg.rf.dcf39b121afb05c7fde8cfade202d2fa.jpg: 640x640 (no detections), 78.8ms\n",
            "Speed: 1.9ms preprocess, 78.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000238_09_03_124_png_jpg.rf.dcf39b121afb05c7fde8cfade202d2fa.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000247_04_01_165_png_jpg.rf.2821dca1fdaab8b22c37ecc944d7ce55.jpg: 640x640 1 Tumor, 78.8ms\n",
            "Speed: 2.1ms preprocess, 78.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000247_04_01_165_png_jpg.rf.2821dca1fdaab8b22c37ecc944d7ce55.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_07_02_160_png_jpg.rf.d20feac44afefd7fe6931ef1456d8066.jpg: 640x640 1 Tumor, 77.0ms\n",
            "Speed: 2.2ms preprocess, 77.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000103_07_02_160_png_jpg.rf.d20feac44afefd7fe6931ef1456d8066.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000188_03_01_146_png_jpg.rf.0aa9c26b627618f4d2c83082b4ed4ef2.jpg: 640x640 1 Tumor, 78.3ms\n",
            "Speed: 1.5ms preprocess, 78.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000188_03_01_146_png_jpg.rf.0aa9c26b627618f4d2c83082b4ed4ef2.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000238_09_03_268_png_jpg.rf.f09aa86ad3ea702195bd5f35eddd1212.jpg: 640x640 1 Tumor, 77.7ms\n",
            "Speed: 2.1ms preprocess, 77.7ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000238_09_03_268_png_jpg.rf.f09aa86ad3ea702195bd5f35eddd1212.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000247_06_02_201_png_jpg.rf.ef1caa3c734b81d91b329bb15e106192.jpg: 640x640 (no detections), 74.6ms\n",
            "Speed: 2.0ms preprocess, 74.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000247_06_02_201_png_jpg.rf.ef1caa3c734b81d91b329bb15e106192.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000143_04_02_126_png_jpg.rf.a0d17c3818d84c51f0d6c14517c6dc00.jpg: 640x640 (no detections), 80.3ms\n",
            "Speed: 1.6ms preprocess, 80.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000143_04_02_126_png_jpg.rf.a0d17c3818d84c51f0d6c14517c6dc00.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_10_01_166_png_jpg.rf.a4b7ce6d23f601c2ad41c03fa6c23f03.jpg: 640x640 2 Tumors, 79.3ms\n",
            "Speed: 1.6ms preprocess, 79.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000103_10_01_166_png_jpg.rf.a4b7ce6d23f601c2ad41c03fa6c23f03.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000247_06_02_149_png_jpg.rf.4a87a4b933d17a7ef8f7cf8e81ec9de2.jpg: 640x640 1 Tumor, 77.7ms\n",
            "Speed: 1.4ms preprocess, 77.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000247_06_02_149_png_jpg.rf.4a87a4b933d17a7ef8f7cf8e81ec9de2.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000207_04_01_059_png_jpg.rf.80eef1da822745c5220074d7aa04de5f.jpg: 640x640 1 Tumor, 77.9ms\n",
            "Speed: 1.5ms preprocess, 77.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000207_04_01_059_png_jpg.rf.80eef1da822745c5220074d7aa04de5f.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000021_03_01_017_png_jpg.rf.6ed5f9db45f94150d050893798c7ee25.jpg: 640x640 (no detections), 77.7ms\n",
            "Speed: 1.7ms preprocess, 77.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000021_03_01_017_png_jpg.rf.6ed5f9db45f94150d050893798c7ee25.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_11_01_177_png_jpg.rf.81d2f65ea3a0de1b20c4e96430b15374.jpg: 640x640 2 Tumors, 79.0ms\n",
            "Speed: 1.5ms preprocess, 79.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000103_11_01_177_png_jpg.rf.81d2f65ea3a0de1b20c4e96430b15374.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000304_01_01_210_png_jpg.rf.5385972414977833b61eff488f5e2bd1.jpg: 640x640 1 Tumor, 76.8ms\n",
            "Speed: 1.5ms preprocess, 76.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000304_01_01_210_png_jpg.rf.5385972414977833b61eff488f5e2bd1.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000103_02_01_168_png_jpg.rf.76e5e9fffd849b95bf96ae1ed4b1be65.jpg: 640x640 (no detections), 77.7ms\n",
            "Speed: 2.3ms preprocess, 77.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000103_02_01_168_png_jpg.rf.76e5e9fffd849b95bf96ae1ed4b1be65.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/002408_01_01_161_png_jpg.rf.5ab3f5970d7b18ffb4c76a1a9acbf4a9.jpg: 640x640 1 Tumor, 80.2ms\n",
            "Speed: 1.5ms preprocess, 80.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/002408_01_01_161_png_jpg.rf.5ab3f5970d7b18ffb4c76a1a9acbf4a9.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000020_04_01_143_png_jpg.rf.1979d244d1b2bc2c7a61d94fd98cf13e.jpg: 640x640 1 Tumor, 75.6ms\n",
            "Speed: 2.2ms preprocess, 75.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000020_04_01_143_png_jpg.rf.1979d244d1b2bc2c7a61d94fd98cf13e.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000230_05_01_165_png_jpg.rf.785131d9ef12d61057eadfd5e6b257ca.jpg: 640x640 1 Tumor, 77.6ms\n",
            "Speed: 1.5ms preprocess, 77.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000230_05_01_165_png_jpg.rf.785131d9ef12d61057eadfd5e6b257ca.jpg\n",
            "\n",
            "image 1/1 /content/dataset/test/images/000284_02_02_018_png_jpg.rf.19c0aaac855fbc821a82306c3d92f86e.jpg: 640x640 1 Tumor, 78.0ms\n",
            "Speed: 1.5ms preprocess, 78.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Image saved successfully at /content/dataset/test/v11predict/000284_02_02_018_png_jpg.rf.19c0aaac855fbc821a82306c3d92f86e.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Management\n",
        "NOT related to training"
      ],
      "metadata": {
        "id": "LtC4KKGeOx6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Duplicate project folder with no weights included"
      ],
      "metadata": {
        "id": "o1DuLhaSYuOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_folder_contents(src_folder, dest_folder):\n",
        "    # Check if the source folder exists\n",
        "    if not os.path.exists(src_folder):\n",
        "        print(f\"Source folder '{src_folder}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Create destination folder if it doesn't exist\n",
        "    if not os.path.exists(dest_folder):\n",
        "        os.makedirs(dest_folder)\n",
        "\n",
        "    # Iterate through all the files and directories in the source folder\n",
        "    for item in os.listdir(src_folder):\n",
        "        src_path = os.path.join(src_folder, item)\n",
        "        dest_path = os.path.join(dest_folder, item)\n",
        "\n",
        "        # Copy files and directories\n",
        "        if os.path.isdir(src_path):\n",
        "            shutil.copytree(src_path, dest_path, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(src_path, dest_path)\n",
        "\n",
        "    print(f\"All contents copied from '{src_folder}' to '{dest_folder}'.\")\n"
      ],
      "metadata": {
        "id": "tlnvr82fL7io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v8seg_noweights_path = '/content/v8seg_noweights/'\n",
        "v11seg_noweights_path = '/content/v11seg_noweights/'\n",
        "os.makedirs(v8seg_noweights_path)\n",
        "os.makedirs(v11seg_noweights_path)\n",
        "\n",
        "src_folder = '/content/v8seg_out/'\n",
        "copy_folder_contents(src_folder, v8seg_noweights_path)\n",
        "\n",
        "src_folder = '/content/v11seg_out/'\n",
        "copy_folder_contents(src_folder, v11seg_noweights_path)\n",
        "\n",
        "shutil.rmtree(v8seg_noweights_path + '100_epochs/weights')\n",
        "shutil.rmtree(v11seg_noweights_path + '100_epochs/weights')"
      ],
      "metadata": {
        "id": "TjbcxyRMLnqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bef800f-18e6-46ce-eabf-ae9855407dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All contents copied from '/content/v8seg_out/' to '/content/v8seg_noweights/'.\n",
            "All contents copied from '/content/v11seg_out/' to '/content/v11seg_noweights/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save progress to Drive"
      ],
      "metadata": {
        "id": "ycxzHiDKPEA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_dir = '/content/dataset'\n",
        "v8seg_out_path = '/content/v8seg_out'\n",
        "v11seg_out_path = '/content/v11seg_out'\n",
        "v8seg_noweights_path = '/content/v8seg_noweights'\n",
        "v11seg_noweights_path = '/content/v11seg_noweights'\n",
        "\n",
        "drive_dir = \"/content/drive/MyDrive/DL\"\n",
        "\n",
        "shutil.make_archive(dataset_dir, 'zip', dataset_dir)\n",
        "shutil.make_archive(v8seg_out_path, 'zip', v8seg_out_path)\n",
        "shutil.make_archive(v11seg_out_path, 'zip', v11seg_out_path)\n",
        "shutil.make_archive(v8seg_noweights_path, 'zip', v8seg_noweights_path)\n",
        "shutil.make_archive(v11seg_noweights_path, 'zip', v11seg_noweights_path)\n",
        "\n",
        "shutil.move(\"/content/dataset.zip\", os.path.join(drive_dir, \"dataset.zip\"))\n",
        "shutil.move(\"/content/v8seg_out.zip\", os.path.join(drive_dir, \"v8seg_out.zip\"))\n",
        "shutil.move(\"/content/v11seg_out.zip\", os.path.join(drive_dir, \"v11seg_out.zip\"))\n",
        "shutil.move(\"/content/v8seg_noweights.zip\", os.path.join(drive_dir, \"v8seg_noweights.zip\"))\n",
        "shutil.move(\"/content/v11seg_noweights.zip\", os.path.join(drive_dir, \"v11seg_noweights.zip\"))\n",
        "\n",
        "print(\"Files moved successfully to Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAHIaGIsKVJ2",
        "outputId": "a1b56a68-47e4-4b01-c140-fe69d081bdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Files moved successfully to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Restore progress from Drive"
      ],
      "metadata": {
        "id": "JJAwM8_XVsrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('/content/drive/MyDrive/DL/dataset.zip', '/content/')\n",
        "shutil.copy('/content/drive/MyDrive/DL/v8seg_out.zip', '/content/')\n",
        "shutil.copy('/content/drive/MyDrive/DL/v11seg_out.zip', '/content/')\n",
        "shutil.copy('/content/drive/MyDrive/DL/v8seg_noweights.zip', '/content/')\n",
        "shutil.copy('/content/drive/MyDrive/DL/v11seg_noweights.zip', '/content/')\n",
        "\n",
        "shutil.unpack_archive('dataset.zip', '/content/dataset/')\n",
        "shutil.unpack_archive('v8seg_out.zip', '/content/v8seg_out/')\n",
        "shutil.unpack_archive('v11seg_out.zip', '/content/v11seg_out/')\n",
        "shutil.unpack_archive('v8seg_noweights.zip', '/content/v8seg_noweights/')\n",
        "shutil.unpack_archive('v11seg_noweights.zip', '/content/v11seg_noweights/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U2RDzBh0mHeb",
        "outputId": "5b717e75-73ee-413d-fa5c-a230e0af0478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/obb_project.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}